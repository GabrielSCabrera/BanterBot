import openai
import os

from banterbot.data import constants
from banterbot.data.openai_models import OpenAIModel
from banterbot.utils.message import Message
from banterbot.utils.spacy_utils import SpacyUtils

# Set the OpenAI API key
openai.api_key = os.environ.get(constants.OPENAI_API_KEY)


class OpenAIManager:
    """
    OpenAIManager is a class that manages the interaction with the OpenAI API for generating responses based on user
    messages. It provides methods to send messages to the API and receive responses either as a complete string or as a
    stream of response blocks.
    """

    def __init__(self, model: OpenAIModel) -> None:
        """
        Initializes an OpenAIManager instance for the specified model.

        Args:
            model (OpenAIModel): The OpenAI model to use, must be of type OpenAIModel (see `/data/openai_models`).
        """
        # Save the given OpenAIModel as an instance attribute
        self._model = model

    def _count_tokens(self, messages: list[Message]) -> int:
        """
        Counts the number of tokens in a given set of messages.

        Args:
            messages (list[Message]): A list of class `Message` instances.

        Returns:
            int: The number of tokens in the given messages.
        """
        # Set a starting token count of 3 to account for the start prompt and AI response prefix
        num_tokens = 3

        # Count the number of tokens for each message in the input list
        for message in messages:
            num_tokens += message.count_tokens()

        return num_tokens

    def _response_parse_stream(self, response: Iterator) -> Generator[list[str, ...], None, bool]:
        """
        Parses a streaming response from the OpenAI API and yields individual messages as they are received.

        Args:
            response (Iterator): The streaming response object.

        Yields:
            Generator[list[str], None, None]: Lists of split sentences as blocks
        """
        # Initialize interruption flag and response text
        self._interrupt = False
        text = ""

        # Iterate over the response chunks
        for chunk in response:

            # Extract the delta, which contains the new text from the AI
            delta = chunk["choices"][0]["delta"]

            # If the interruption flag has been set raise StopIteration
            if self._interrupt:
                # Indicate that the generator did not complete its iterations
                return False

            # If there is new content in the delta, add it to the response text and parse it
            if "content" in delta.keys():
                text += delta["content"]

            # If new text has been detected, split it into sentences and yield all completed sentences
            if re.search(SENTENCE_SPLIT, text):
                sentences = SpacyUtils.segment_sentences(text)
                text = sentences[-1]
                yield sentences[:-1]

        # Yield the remaining text
        sentences = SpacyUtils.segment_sentences(text)
        yield sentences
        # Indicate that the generator completed its iterations
        return True

    def _request(self, messages: list[Message], stream: bool, **kwargs) -> Union[Iterator, str]:
        """
        Sends a request to the OpenAI API to generate a response based on the given messages and other parameters. Can
        return a stream, or can wait until the entire response is complete and return a string.

        Args:
            messages (list[dict[str, str]]): A list of messages as dictionaries containing message information.
            stream (bool): Whether the request should return an iterable stream, or the entire response text at once.
            **kwargs: Additional parameters to be passed to the OpenAI API request - some are not modifiable.

        Returns:
            Union[Iterator, str]: The response generated by the OpenAI API as an iterator, or as a string.
        """
        # Add relevant attributes to the kwargs parameter dictionary
        kwargs["model"] = self._model.name
        kwargs["n"] = 1
        kwargs["stream"] = stream
        kwargs["messages"] = messages
        kwargs["max_tokens"] = self._model.max_tokens - self._count_tokens(messages=messages)

        # Keep track of whether or not the request was successful
        success = False
        # Retry the request if it fails due to rate limiting
        for i in range(config.retry_attempt_limit):
            try:
                # Send request to OpenAI API and retrieve response
                response = openai.ChatCompletion.create(**kwargs)
                # Set the success flag and exit the loop
                success = True
                break
            except (openai.error.RateLimitError, openai.error.APIError):
                # Wait for a short period before retrying the request
                time.sleep(0.25)

        if not success:
            # If the request fails after all retries, raise an exception
            raise openai.error.APIError

        if stream:
            # Return the response as an iterator object
            return response

        elif not stream:
            # Extract the generated response from the response object and strip whitespace
            return response.choices[0].message.content.strip()

    def prompt(self, messages: list[Message], **kwargs) -> list[str, ...]:
        """
        Takes in a message from the user, appends it to the conversation history, and sends it to the AI for a response.
        The response is then segmented into sentences and returned as a list of strings.

        Args:
            messages (list[Message]): A list of class `Message` instances.
            **kwargs: Additional parameters to be passed to the OpenAI API request - some are not modifiable.

        Returns:
            list[str, ...]: A list of strings, each string being a sentence in the response.
        """
        # Send messages to AI and get response
        response = self._request(messages=messages, stream=False, **kwargs)

        # Split the response into individual sentences
        sentences = SpacyUtils.segment_sentences(response)

        return sentences

    def prompt_stream(self, messages: list[Message], **kwargs) -> Generator[list[str, ...], None, None]:
        """
        Sends the user message to the AI and generates a stream of response blocks parsed from the AI's stream.

        Args:
            messages (list[Message]): A list of class `Message` instances.
            **kwargs: Additional parameters to be passed to the OpenAI API request - some are not modifiable.

        Yields:
            Generator[list[str], None, None]: Lists of split sentences as blocks
        """
        # Make a stream request to the AI, passing the history and context messages
        response = self._request(messages=messages, stream=True, **kwargs)

        # Parse the response stream and yield each response block
        for block in self._response_parse_stream(response=response):
            yield block
